{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup  \n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "#set topages\n",
    "page_num = 20\n",
    "page_start = 0\n",
    "\n",
    "AI = 'AI'\n",
    "CV = 'computer+vision'\n",
    "NLP = 'natural+language+processing'\n",
    "DS = 'data+science'\n",
    "ML = 'machine+learning'\n",
    "domain = ML\n",
    "\n",
    "NY = 'New+York'\n",
    "SF = 'San+Francisco'\n",
    "SE = 'Seattle'\n",
    "region = SE\n",
    "\n",
    "#set start page\n",
    "page_url = 'https://www.indeed.com/jobs?q=' + domain + '&l=' + region\n",
    "print(page_url)\n",
    "# headers ={'User‐Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKi t/537.36 (KHTML, like Gecko) Chrome/75.0.3770.142 Safari/537.36'}\n",
    "\n",
    "#data\n",
    "companyName = []\n",
    "companyLocation = []\n",
    "ratingNumber = []\n",
    "salary = []\n",
    "jobTitle = []\n",
    "url_add = []\n",
    "url_text = []\n",
    "date = []\n",
    "extract_date = []\n",
    "\n",
    "while(True):\n",
    "    page_num = page_num -1\n",
    "    page_start = page_start+10\n",
    "    if(page_num<0):\n",
    "        print('all page done...')\n",
    "        break\n",
    "    else:\n",
    "        print('left page...',page_num+1)\n",
    "\n",
    "        page = requests.get(page_url)    \n",
    "        if (page.status_code==200):   \n",
    "                soup = BeautifulSoup(page.content, 'html.parser') \n",
    "                time.sleep(1)\n",
    "                \n",
    "                #next page\n",
    "                page_url = page_url + '&start=' + str(page_start)\n",
    "#                 temp=soup.find('ul',class_='pagination-list')\n",
    "#                 temp=temp.find_all('a',href=True)\n",
    "#                 next_url = 'https://www.indeed.com'+str(temp[0]['href'])\n",
    "#                 page_url = next_url\n",
    "\n",
    "                ##find main zone\n",
    "                temp=soup.find('div',id='mosaic-zone-jobcards')\n",
    "                temp=soup.find_all('a',attrs={\"id\":re.compile(r\"sj_(\\s\\w+)?|job_(\\s\\w+)?\")})\n",
    "\n",
    "                for i in temp:\n",
    "                    #companyName\n",
    "                    result=i.find('span',class_='companyName')\n",
    "                    if (result==None):\n",
    "                        companyName.append('None')\n",
    "                    else:\n",
    "                        companyName.append(result.text)\n",
    "\n",
    "                    #companyLocation\n",
    "                    result=i.find('div',class_='companyLocation')\n",
    "                    if (result==None):\n",
    "                        companyName.append('None')\n",
    "                    else:\n",
    "                        companyLocation.append(result.text)\n",
    "\n",
    "                    #ratingNumber\n",
    "                    result=i.find('span',class_='ratingNumber')\n",
    "                    if (result==None):\n",
    "                        ratingNumber.append('None')\n",
    "                    else:\n",
    "                        ratingNumber.append(result.text)\n",
    "\n",
    "                    #salary\n",
    "                    result=i.find('div',class_='metadata salary-snippet-container')\n",
    "                    if (result==None):\n",
    "                        salary.append('None')\n",
    "                    else:\n",
    "                        salary.append(result.text)\n",
    "\n",
    "                    #job title（remove new）\n",
    "                    result=i.find('h2',attrs={\"class\":re.compile(r\"jobTitle(\\s\\w+)?\")})\n",
    "                    if (result==None):\n",
    "                        jobTitle.append('None')\n",
    "                    else:\n",
    "                        jobTitle.append(result.text)\n",
    "                        \n",
    "                    #date\n",
    "                    result=i.find('span',class_='date')\n",
    "                    if (result==None):\n",
    "                        date.append('None')\n",
    "                    else:\n",
    "                        date.append(result.text)\n",
    "                    \n",
    "                    #extract date\n",
    "                    extract_date.append(datetime.now())\n",
    "\n",
    "                    #url\n",
    "                    result = i['href']\n",
    "                    if (result==None):\n",
    "                        url_add.append('None')\n",
    "                    else:\n",
    "                        url_add.append('https://www.indeed.com'+str(result))\n",
    "\n",
    "                    #url_content\n",
    "                    page2 = requests.get('https://www.indeed.com'+str(result))    \n",
    "                    if (page2.status_code==200):   \n",
    "                            soup2 = BeautifulSoup(page2.content, 'html.parser')\n",
    "                            time.sleep(1)\n",
    "                            result=soup2.find('div',id='jobDescriptionText')\n",
    "\n",
    "                            if (result==None):\n",
    "                                url_text.append('None')\n",
    "                            else:\n",
    "                                url_text.append(result.text)\n",
    "\n",
    "\n",
    "# build dataframe\n",
    "data1 = {\n",
    "\"JobTitle\":jobTitle,\n",
    "\"CompanyName\":companyName,\n",
    "\"CompanyLocation\":companyLocation,\n",
    "\"CompanyRating\":ratingNumber,\n",
    "\"Salary\":salary,\n",
    "\"Date\":date,\n",
    "\"Extract_Date\":extract_date,\n",
    "\"Content_url\":url_add,\n",
    "\"Content_text\":url_text\n",
    "}\n",
    "df1 = pd.DataFrame(data1)\n",
    "\n",
    "df1.to_csv(domain+'_'+region+'.csv',index=False,header=True)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Untitled14.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
